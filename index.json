[{"authors":null,"categories":null,"content":"I am currently a master student in Robotics at EPFL, Switzerland. I am working as a research assistant at BioRob on deep learning methods for furniture skeleton localisation, which is a continuation to my semester project on Omnibot: Mobile furniture baseline development supervised by Prof. Ijspeert, Dr. Bolotnikova and Dr. Crespi in Fall, 2021. In Fall 2020, I conducted my semester project at Ramdya Lab on improving an automated system for optogenetic experimentation supervised by Prof. Ramdya, Dr. Lobato and Dr. Morales.\nI received my double bachelor degree in Mechatronics Engineering from Tongji University, China and University of Applied Sciences Aachen, Germany. During that period, I worked on automatic real \u0026amp; synthetic 6D-pose detection dataset generation with Prof. Kallweit, Heiko Engemann and Intelligent Industry 4.0 with Prof. Nan Xie.\n\u0026ldquo;Instead of codes that are only survivable on a computer, I prefer my efforts to be shown vividly beyond the screen.\u0026rdquo; For this reason, I didn\u0026rsquo;t specialize in algorithms or coding only but managed to get down to real robots and to be interdesciplinary. My main research interest is in incorporating state-of-art algorithms to help robotic system perceive human behaviours and react smartly and interactively, which is crucial for social and service robots.\n Download my resumé. --\r","date":1607817600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607817600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://chuanfang-ning.github.io/author/chuanfang-ning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chuanfang-ning/","section":"authors","summary":"I am currently a master student in Robotics at EPFL, Switzerland. I am working as a research assistant at BioRob on deep learning methods for furniture skeleton localisation, which is a continuation to my semester project on Omnibot: Mobile furniture baseline development supervised by Prof.","tags":null,"title":"Chuanfang Ning","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://chuanfang-ning.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"Supervisor: Prof. Auke Ijspeert, Prof. Alexandre Alahi, Dr. Anastasia Bolotnikova, Dr. Alessandro Crespi, \rStudents: Chuanfang Ning, Lixuan Tang \rI am working as a Research Assistant at Biorob this semester to continue on my semester project : \u0026ldquo;Omnibot: Mobile Furniture Baseline Development\u0026rdquo; in collaboration with Lixuan Tang.\n We are extending the Omnibot design to multiple copies which prepares for a swarm robotics framework. We are evaluating our current furniture skeleton localisation model on the Omnibot with the help of key-point localisation with Optitrack system. We are facilitating the skeleton localisation model with real and synthetic data for Omnibot use cases. We will improve the network structure based on the test performance.  To be updated.\n","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643673600,"objectID":"64088cab195ba98a751570ca751124d7","permalink":"https://chuanfang-ning.github.io/project/omnibot-skeleton-localisation/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/project/omnibot-skeleton-localisation/","section":"project","summary":"Extending Omnibot into swarm robotic framework and improving localisation with furniture skeleton detection network.","tags":["Mechatronics Robotics","Deep Learning and Data Sciences","Ongoing"],"title":"(Ongoing) Deep learning method for mobile furniture skeleton localisation ","type":"project"},{"authors":null,"categories":null,"content":"Course project for CIVIL-459 Deep learning for autonomous vehicles\rLecturer: Prof. Alexandre Alahi \rGuide an autonomous driving car to react to certain patterns in noisy environments.\nOngoing project.\n","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643673600,"objectID":"57ab7486ea41f32ffb6f9dc4ced2d4e7","permalink":"https://chuanfang-ning.github.io/project/dl-autonomous/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/project/dl-autonomous/","section":"project","summary":"Guide an autonomous driving car to follow patterns in noisy environments.","tags":["Vision Graphics","Deep Learning and Data Sciences","Ongoing"],"title":"(Ongoing) Human-robot tandem race","type":"project"},{"authors":null,"categories":null,"content":"Final project for CS-401 Applied Data Analysis\rStudents: Chuanfang Ning, Irvin Mero Zambrano, Thomas Castiglione, Guoyuan Liu \rLecturer: Prof. Robert West \rQuotebank is a dataset of 235 million unique, speaker-attributed quotations that were extracted from 196 million English news articles crawled from over 377 thousand English web domains. The project aims at analyzing the quotebank mentions in between year 2015 and 2020 to reveal the bi-polar political landscape of America. Keypoints in the project:\n data cleaning and preprocessing pipeline from original Quotebank quotations, Wikidata dump and Partisan Audience Bias Scores Dataset. political mention analysis pipeline including topic, sentiment and bias analysis. political network analysis pipeline including network construction, community/centrality analysis and edge/node feature detection. visualisation pipeline for the analysis above with interactive network graphs.  More details to be found in our code and website.\n","date":1639612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639612800,"objectID":"2b3b7dd8d243548b28f4c83e03393c5b","permalink":"https://chuanfang-ning.github.io/project/ucite/","publishdate":"2021-12-16T00:00:00Z","relpermalink":"/project/ucite/","section":"project","summary":"An American politician network analysis based on 270k political mentions filtered from 235 Mio. quotations in Quotebank.","tags":["Deep Learning and Data Sciences","Data Processing","Data Visualisation"],"title":"U_Cite: America politician network analysis based on Quotebank","type":"project"},{"authors":null,"categories":null,"content":"Final project for EE-473 Embedded Systems\rStudents: Alexander Sigrist, Chuanfang Ning \rLecturer: Prof. René Beuchat \r Master unit design for LT24 LCD display ILI9341 controller on DE0-Nano-SoC FPGA. Softcore processor hardware programming with VHDL in Quartus. Simulation and verification of the design in Modelsim. Integration of the LCD display with a TRDB-D5M camera of our partner group to build a live streaming system.  Demo with camera:\nMore details can be found in the report.\n","date":1639526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639526400,"objectID":"31288b7763c4200fc40757acf18bf95d","permalink":"https://chuanfang-ning.github.io/project/fpga/","publishdate":"2021-12-15T00:00:00Z","relpermalink":"/project/fpga/","section":"project","summary":"Design of a LT24 LCD controller interface on Intel FPGA.","tags":["Embedded Systems"],"title":"FPGA master unit design for LT24 Display on DE0-Nano-SoC","type":"project"},{"authors":null,"categories":null,"content":"Semester Project 2021 Fall at BioRob and Reconfigurable Robotics Lab with 6.0/6.0.\nThis project is funded by the CIS Research Pillar, Intelligent Assistive Robotics Grant. \rSupervisor: Prof. Auke Ijspeert, Dr. Anastasia Bolotnikova, Dr. Alessandro Crespi, \rProject Goal The project aims at extending an Omni-directional Drive Robot Platform from scratch to a fully functional mobile robot that can drive furniture around according to user needs. The project includes 4 parts:\n Mechanical part:  Design and implement attachment-configuration from the robot platform to various kinds of furniture. Extend the platform modules according to user demands (Bluetooth, LED, sensors).   Electronic part:  Extend the default board coming with the robot platform from a limited stand-alone system to a system allowing for interactive control and module extension. Optimizing the circuit design with our custom PCB. Implement the teleoperation of sensors/actuators on the robot platform with ROS_Serial via Bluetooth.   Algorithm part:  Real-time localisation with Optitrack. Navigation with simplified visibility graph and A*. Interactive control including program, voice and gesture interfaces. Android application development for mobile furniture remote control.    Project repo archived at internal Gitlab (requires EPFL access).\nThe Android application control interface with joystick and buttons.\nUpdate 2022-02: Our custom PCB arrives! Demo playlists:\n\rMore details to be found in the report and slides.\n","date":1639526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639526400,"objectID":"5b72bf24af2177a97bbdc10ebd59550f","permalink":"https://chuanfang-ning.github.io/project/omnibot-baseline/","publishdate":"2021-12-15T00:00:00Z","relpermalink":"/project/omnibot-baseline/","section":"project","summary":"Development of a mobile robot that drives furniture around. Includes mechanical adaptation, electronics design, interactive control (program, gesture, voice) and Android application development.","tags":["Mechatronics Robotics","Embedded Systems"],"title":"Omnibot: Mobile furniture baseline development","type":"project"},{"authors":null,"categories":null,"content":"Final project for MICRO-452 Basics of mobile robotics with 6.0/6.0\rStudents: Chuanfang Ning, Erfan Etesami, Hugo Miranda Queiros, Laura Boca de Giuli \rLecturer: Prof. Francesco Mondada \rThis is the course project of Basics of mobile robotics. The project goal is to have a minimal but comlpete mobile robot pipeline design on Thymio robot. The project covers basic components of a mobile robotic task as shown below:\n global mapping with Arcuo markers and HSV path planning with A* on visibility graph. kalman filter with odometry and camera. motion control with waypoints following. local avoidance with left-wall following. robust to kidnap and unexpected disturbance. live visualisation of camera, filtered estimation and uncertainties.  Demo:\n  ","date":1639180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639180800,"objectID":"a261a8d14dda58b06181cca5477cc199","permalink":"https://chuanfang-ning.github.io/project/thymio-simple/","publishdate":"2021-12-11T00:00:00Z","relpermalink":"/project/thymio-simple/","section":"project","summary":"A minimal design for a full mobile robot system on Thymio with vision, localisation, global/local navigation and filtering.","tags":["Mechatronics Robotics"],"title":"Basic mobile robot design with Thymio","type":"project"},{"authors":null,"categories":null,"content":"Final project for MICRO-553 Haptic human robot interfaces\rStudents: Chuanfang Ning, Dorian Bignet \rLecturer: Prof. Mohamed Bouri \rSupervisor: Dr. Evgenia Roussinova \rThe aim of this specialization project is to design and implement a control strategy allowing a user to control the haptic paddle through the contraction of a muscle, which is recorded by electromyography (EMG). The lab specialisation includes:\n processing and filtering of raw EMG signal developing EMG control strategies of haptic paddle applying the control strategies to 3 different application:   Assistive use case: facilate human in strength tasks Rehabilitation use case: reinforce muscle fibers and help reinnervation after a stroke Grasping use case: combined position \u0026amp; torque control for hand prosthesis  More details can be found in the report.\n\r Fig. 1 Band-pass filtered signal\r\r Fig. 2 RMS filtered signal\r\r Fig. 3 Moving threshold filtered signal\r\r\r\r Fig. 4 Tremored EMG control\r\r Fig. 5 Tremor-free EMG control (+moving threshold)\r\r\r","date":1624233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624233600,"objectID":"5739226d0362b1d8c2de10d541a8378f","permalink":"https://chuanfang-ning.github.io/project/emg-haptics/","publishdate":"2021-06-21T00:00:00Z","relpermalink":"/project/emg-haptics/","section":"project","summary":"EMG control of haptic paddle and application in three use cases.","tags":["Control","EMG","rehabilitation"],"title":"EMG Control of haptic paddle","type":"project"},{"authors":null,"categories":null,"content":"Final project for CS-341 Introduction to computer graphics. Top 3 projects of the year.\rStudents: Benjamin Hug, Chuanfang Ning, Yannick Goumaz \rLecturer: Prof. Mark Pauly \r WebGL programming to render a scene with a portal on GPU. Across-world Shader \u0026amp; Lighting model implementation. Navigation in the scene with keyboard and teleoperation when entering portals. Fluid distortion effect on portal surface with special shader. Switch portal connection when player lookes away from it. (Depth buffer check)  Demo:\n  Our team won the top-3 ICG project for year 2021. Full stream here.\n","date":1622764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622764800,"objectID":"b0f40dd9b6b402b5bcd3f2ec8dcbebdd","permalink":"https://chuanfang-ning.github.io/project/webgl-portal/","publishdate":"2021-06-04T00:00:00Z","relpermalink":"/project/webgl-portal/","section":"project","summary":"A playable scene with a portal connected to 3 different worlds, the portal connection switched looking away from the portal.","tags":["Vision Graphics"],"title":"Multi-dimensional portal rendering with WebGL","type":"project"},{"authors":null,"categories":null,"content":"Final project for EE-451 Image Analysis and Pattern Recognition\rStudents: Chuanfang Ning, Noppawit Lertutsahakul, Raphael Uebersax \rLecturer: Prof. Jean-Philippe Thiran \rProject description\r Poker and dealer segmentaion from raw images with disturbances. Bayesian classifier for poker suit. MLP classifier for poker digits. Predict the player rank according to game rules.  ","date":1620345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620345600,"objectID":"3dceffa95ac888233be67d5c6cc4e7ed","permalink":"https://chuanfang-ning.github.io/project/pokergame/","publishdate":"2021-05-07T00:00:00Z","relpermalink":"/project/pokergame/","section":"project","summary":"Intelligent referee to judge poker game winner from overview snapshots.","tags":["Vision Graphics"],"title":"Automatic Poker Game Referee","type":"project"},{"authors":null,"categories":null,"content":"Final project for MICRO-453 Robotics Practicals with 5.8/6.0\rStudents: Chuanfang Ning, Jianhao Zheng, Yujie He\r Example page: https://go.epfl.ch/ros_basics_final_2021\n⭐ 2021/04: Update our project Report !\n 🔑 Keywords Thymio, PID, Way following, Obstacle avoidance, Pledge algorithm, Aruco marker, Sim2Real, Gazebo\n🔨 How to use?   visualize Thymio in RViz\nroslaunch ros_basics_exercise thymio_simple_rviz.launch\r   simulate Thymio robot in Gazebo with an interactive window\nroslaunch ros_basics_control simu_thymio.launch\r   adding waypoints and obstacle for the robot\nroslaunch ros_basics_control simu_thymio.launch\rroslaunch ros_basics_exercise set_simu_waypoints_obstacle.launch\r   tune with rqt tools (rqt_plot, rqt_reconfigrure, rqt_image_show)\nroslaunch ros_basics_control simu_thymio.launch\rroslaunch ros_basics_exercise tune_with_rqt.launch\r   visualize the rosbag files\nroslaunch ros_basics_exercise view_with_rosbag.launch\r   extract pose and sensor information from rosbag files\nroslaunch ros_basics_exercise view_with_rosbag.launch\r# open a new terminal\rrosrun ros_basics_exercise topic_reader.py\r   plot trajectory comparison between real and simulation (using matlab)\ncd results_from_bag/\r# run `plot_traj_comp.m` in MATLAB\r   connect to the real Thymio\npip install thymiodirect\rroslaunch ros_basics_control real_thymio.launch\r   🎒Example rosbag files  rosbags can be downloaded from Google Drive\n For more info, you can refer to readme.md in ./src/ros_basics_exercise/rosbags/ folder.\n⭐ Acknowledgement Thanks to Vaios Papaspyros and Rafael Barmak from MOBOTS at EPFL for the amazing course tutorials !\n","date":1617321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617321600,"objectID":"498b727aee16df6348ec37267f1ac222","permalink":"https://chuanfang-ning.github.io/project/sim2real-thymio/","publishdate":"2021-04-02T00:00:00Z","relpermalink":"/project/sim2real-thymio/","section":"project","summary":"Implemented autonomous navigation with obstacle avoidance of the Thymio-II robot from simulation in Gazebo to real-world tests.","tags":["Mechatronics Robotics"],"title":"Sim2Real Development for Thymio with ROS","type":"project"},{"authors":null,"categories":null,"content":"Final project for ME-425 Model Predictive Control\rLecturer: Prof. Colin Jones \r MPC controller design in matlab with Gurobi and Casadi optimizer. linear MPC for decomposed quadcopter systems offset-free MPC tracking regulator in case of fluctuating quadcopter mass non-linear MPC for integral quadcopter system  \r Trajectory following with combined linear MPC controller\r\r Trajectory recovery from mass disturbance with offset-free MPC controller\r\r Trajectory following with non-linear MPC controller\r\r\r\r Quadcopter states during offset-free MPC simulation\r\r Quadcopter states during NMPC simulation\r\r","date":1609718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609718400,"objectID":"75485a2b239c1a6488110c20379f0218","permalink":"https://chuanfang-ning.github.io/project/mpc-mini-project/","publishdate":"2021-01-04T00:00:00Z","relpermalink":"/project/mpc-mini-project/","section":"project","summary":"Simple MPC and NMPC design for a quadcopter in Matlab with Gurobi and Casadi solver.","tags":["Control","Model Predictive Control"],"title":"MPC Control of Quadcopter","type":"project"},{"authors":null,"categories":null,"content":"Semester Project 2020 Fall at Ramdya Lab (Neuroengineering Laboratory) with 6.0/6.0.\nSupervisor: Prof. Pavan Ramdya, Dr. Victor Lobato, Dr. Daniel Morales, \rProject goal This semester project aims at redesigning, prototyping and programming the carousel, gripper and arena module for the old Optobot system to increase its precision on carrying out optogenetic experimentation, which helps to expose Drosophilas to accurately controlled stimuli and record their behaviors. More info on the lab page.\nThe redesigned model addressed 3 catastrophic failure modes of the previous design(rotation error, gripping error and returning error) which have made the unsupervised experiments impossible.\n\r Rotation error (misalignment breaks the shelf)\r\r gripping error (invalid data with empty frames)\r\r returning error (remaining container breaks the shelf)\r\r\rProject content  design and model new carousel, gripper and arena module to resolve the diagnosed failure modes from hardware. close the control loop of motor motion with new sensor and increase system precision from software. manufacture the prototype of the design in the workshop. validate and evolve the design until a functional version. adapt control logic and update programs to fit the new design.  Demo: Note that the shelf material was out of stock by the semester end. The demo is a show case without shelf. A pink marker is pasted on carousel base to represent the rotating shelves.\n  More details to be found in the report and slides.\n","date":1607990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607990400,"objectID":"d6041239567f1852421c9d8d8af51357","permalink":"https://chuanfang-ning.github.io/project/optobot/","publishdate":"2020-12-15T00:00:00Z","relpermalink":"/project/optobot/","section":"project","summary":"Improvement of an automation system that helps with the neurogenetics experimentation. Includes mechanical design, prototyping and verification, control process programming with C++ on Arduino and user control interface programming with python.","tags":["Mechatronics Robotics","Automation Systems","Embedded Systems"],"title":"Improvement on Optobot - an Automated system for Neurogenetics Experimentation","type":"project"},{"authors":["Chuanfang Ning"],"categories":["Demo","教程"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Guide and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://chuanfang-ning.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":null,"categories":null,"content":"Final project for MICRO-507 Legged Robots\rStudents: Chuanfang Ning, Guilain Brunoro, Mingchi Hou \rLecturer: Prof. Auke Ijspeert \r kinetic, dynamic and impact map modelling of a three-link-biped walker in Matlab animated the walker in simulation given the model, actuation and disturbance implemented a CPG controller to mimic the torque control obtained from a PD controller evaluated the control metrics in terms of robustness against perturbations, walking speed, gait length/frequencies  Control law: mixed control with CPG (30% feedforward) + PD(70% feedback). Object function:\n$$f(p)=w_1\\times|\\dot{x}\\_{hip}-\\dot{\\bar{x}}\\_{hip}(p)|+w_2\\times CoT(p)+w_3\\times| z\\_{hip}-\\bar{z}\\_{hip}(p)|+w_4\\times| f\\_{rq}-\\bar{f}\\_{rq}(p)|$$\rThe object function always minimizes the cost of transfer and tries to mimic the pattern generated by a PD controller.\rThe object function can be edited to generate gait with certain step length or frequency or maximize the gait speed.\rDemo for our project:   ","date":1607644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607644800,"objectID":"8ef0f32c436e65770cbba3fd9014086e","permalink":"https://chuanfang-ning.github.io/project/cpg-biped-walker/","publishdate":"2020-12-11T00:00:00Z","relpermalink":"/project/cpg-biped-walker/","section":"project","summary":"CPG controll for a three-link biped walker locomotion in Matlab simulation.","tags":["Control","Legged Robots","Locomotion"],"title":"CPG Control of three-link biped walker","type":"project"},{"authors":null,"categories":null,"content":"Supervisor: Prof. Stephan Kallweit, Heiko Engemann \rThis project is a continuation to my semester project: Automatic 6D Pose Detection Dataset Capture with UR5 Robot. We extended our real-world dataset generation pipeline by adding a parallel synthetic dataset generation pipeline, which allows us to improve the performance of our object detection model by combining synthetic and real-world data.\nWe used Unreal Engine 4 to generate a 6D pose detection dataset: AutoSynPose with 6 Mio. subsegments for 5 YCB objects using 97 rendering locations in 12 different environments.\nThis is done by extending the open-source NVIDIA Deep learning Dataset Synthesizer (NDDS) plugin by\n extending the domain randomization from stochastic distractors to rigid bodies( roughness, specular, metallic and HUE shift). extending the stochastic distractors with realistic distractor set (YCB objects) adding realistic collision and gravity feature adding automatic perspective randomization logging domain randomization parameters and enabling clustering of big dataset into sub-datasets accordingly.  Demo:   More details to be found in our paper.\n","date":1591488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591488000,"objectID":"7d3b683916219e68af2e3e61ba52f56b","permalink":"https://chuanfang-ning.github.io/project/ue4-dataset/","publishdate":"2020-06-07T00:00:00Z","relpermalink":"/project/ue4-dataset/","section":"project","summary":"A pipeline for the generation of synthetic datasets with high object variance for 6D object pose estimation that enables a completely automated generation process based on predefined settings.","tags":["Deep Learning and Data Sciences","Vision Graphics","Dataset"],"title":"AutoSynPose: Automatic Generation of Synthetic Datasets for 6D Object Pose Estimation","type":"project"},{"authors":null,"categories":null,"content":"Semester project at FH Aachen, Wintersemester 2019 \rSupervisor: Prof. Stephan Kallweit, Heiko Engemann \rThis project provides an automatic pipeline of creating a real-world 6D pose detection dataset with the help of a wandering UR5 robotic arm on a mobile platform. The 3D model of the training object and its initial offset to the robot base are to be provided. The dataset consits of RGB images, depth images, segmentation masks and 6D poses for the training object.\nThis automatic pipeline is mainly targeted at industrial manipulating or quality inspection tasks, where a deep learning model is used to identify/inspect products with accurate known models. The considered application flowchart for the project is shown as in the figure below:\nIn this project, the UR5 robot is mounted on a mobile platform and holds an Intel D435 RGBD camera to wander around the object of interest with the following pattern:\n\r Robot stop at a place to scan 1/8 sphere space of the training object\r\r At each scanning point the robot turns the sensor to get multi-perspective images\r\r\rThe RGB and depth images are captured by the sensor and the ground truth of object\u0026rsquo;s 6D poses, instance/segmentation mask and 3D bounding boxes are calculated from the camera matrix corresponding to robot\u0026rsquo;s joint states in real time.\nExperiment:\n\r Robot and environment setup\r\r Captured dataset samples\r\r\rResult:\nTo evaluate the quality of ground truth generated by the method, we annotated the ground truth directly from RGB images once again and checked the BF-Score and IoU of real ground truth with the ground truth generated by our method. The subsegment with YCB bottle got an average score of 0.5156 (BF) and 0.8451 (IoU). The subsegment with Lego car got an average score of 0.8618 (BF) and 0.8551 (IoU). (Left) Generated ground truth, (Middle) Manually annotated ground truth, (Right) Overlay for error checks\rDemo:\nA simple show case in Gazebo simulation:   More details to be found in the code.\n","date":1576972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576972800,"objectID":"e23f286ba3fad97e170910a3b0ef96e7","permalink":"https://chuanfang-ning.github.io/project/ur5-dataset/","publishdate":"2019-12-22T00:00:00Z","relpermalink":"/project/ur5-dataset/","section":"project","summary":"Control a UR5 robot on a mobile platform to wander around objects of interest to take images for generating 6D pose detection dataset.","tags":["Mechatronics Robotics","Deep Learning and Data Sciences","Dataset"],"title":"Automatic 6D Pose Detection Dataset Capture with UR5 Robot","type":"project"},{"authors":null,"categories":null,"content":"Projektmanagement für Fachmodul 8518018: Mechatronische Systeme und Embedded Systems an FH Aachen\r Mechanischer Umbau eines bewegungslosen Regal zu einem angetriebenen Regal von DS3120 Servomotor. Arduino Programmierung in C++ für die Prozesssteuerung von Motorbewegung und LCD Bildschirm unter Benutzerinteraktion. Nach Entnahme einer korrekten Anzahl von Teilen nach dem Auftrag gibt das System die Kiste frei und liefert die nächste Kiste mit Teilen zu. Informationen über die zu entnehmenden Teilen und Warnungenen sind auf LCD Bildschirm angezeigt.  Weitere Details finden Sie in Slides.\n","date":1573084800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573084800,"objectID":"4e63adcfc63a80d2d2d3c8333bc7b62e","permalink":"https://chuanfang-ning.github.io/project/karakuri-waegesystem/","publishdate":"2019-11-07T00:00:00Z","relpermalink":"/project/karakuri-waegesystem/","section":"project","summary":"Umbauen eines mechanischen Karakuri Systems in einem digitalen System, das bei der Aufgabe Teileverpackung hilft.","tags":["Automation Systems","Embedded Systems"],"title":"Digitales Karakuri-Intelligente Wägesystem (auf Deutsch)","type":"project"},{"authors":null,"categories":null,"content":"Supervisor: Prof. Yu Wang, Xiaoyang Zhang \rGroup project with patent (CN110193929A)\rMembers: Chuanfang Ning, Yizhen Li, Yucheng Zhang, Zeling Long \r Designed and prototyped a supporting mechanism with 400 pins that can move and lock independently to support different less-supported shape during additive manufacturing. Developed a C++ program with simple user interface to convert a 3D-print model automatically into a complementary supporting shape. Drove 25 servo motors to drive the 400 pins to form the generated supporting shape.  ","date":1570924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570924800,"objectID":"b09998566995327c9ac62a733f61b8f2","permalink":"https://chuanfang-ning.github.io/project/pin-matrix/","publishdate":"2019-10-13T00:00:00Z","relpermalink":"/project/pin-matrix/","section":"project","summary":"An automation system to form a complemntary shape for less-supported shape in 3D printing.","tags":["Automation Systems"],"title":"Pin matrix support mechanism for 3D printing","type":"project"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python\rimport pandas as pd\rdata = pd.read_csv(\u0026quot;data.csv\u0026quot;)\rdata.head()\r```\r renders as\nimport pandas as pd\rdata = pd.read_csv(\u0026quot;data.csv\u0026quot;)\rdata.head()\r Charts Academic supports the popular Plotly chart format.\nSave your Plotly JSON in your page folder, for example chart.json, and then add the {{\u0026lt; chart data=\u0026quot;chart\u0026quot; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\n  (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./line-chart.json\", function(chart) { Plotly.plot('chart-319276845', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })();  You might also find the Plotly JSON Editor useful.\nMath Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}\r{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$\r renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\\\\\r1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$\r renders as\n$$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\n1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid\rgraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r```\r renders as\ngraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r An example sequence diagram:\n```mermaid\rsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r```\r renders as\nsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r An example Gantt diagram:\n```mermaid\rgantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r```\r renders as\ngantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r An example class diagram:\n```mermaid\rclassDiagram\rClass01 \u0026lt;|-- AveryLongClass : Cool\r\u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01\rClass09 --\u0026gt; C2 : Where am i?\rClass09 --* C3\rClass09 --|\u0026gt; Class07\rClass07 : equals()\rClass07 : Object[] elementData\rClass01 : size()\rClass01 : int chimp\rClass01 : int gorilla\rclass Class10 {\r\u0026lt;\u0026lt;service\u0026gt;\u0026gt;\rint id\rsize()\r}\r```\r renders as\nclassDiagram\rClass01 \u0026lt;|-- AveryLongClass : Cool\r\u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01\rClass09 --\u0026gt; C2 : Where am i?\rClass09 --* C3\rClass09 --|\u0026gt; Class07\rClass07 : equals()\rClass07 : Object[] elementData\rClass01 : size()\rClass01 : int chimp\rClass01 : int gorilla\rclass Class10 {\r\u0026lt;\u0026lt;service\u0026gt;\u0026gt;\rint id\rsize()\r}\r An example state diagram:\n```mermaid\rstateDiagram\r[*] --\u0026gt; Still\rStill --\u0026gt; [*]\rStill --\u0026gt; Moving\rMoving --\u0026gt; Still\rMoving --\u0026gt; Crash\rCrash --\u0026gt; [*]\r```\r renders as\nstateDiagram\r[*] --\u0026gt; Still\rStill --\u0026gt; [*]\rStill --\u0026gt; Moving\rMoving --\u0026gt; Still\rMoving --\u0026gt; Crash\rCrash --\u0026gt; [*]\r Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example\r- [x] Write diagram example\r- [ ] Do something else\r renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header |\r| ------------- | ------------- |\r| Content Cell | Content Cell |\r| Content Cell | Content Cell |\r renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Callouts Academic supports a shortcode for callouts, also referred to as asides, hints, or alerts. By wrapping a paragraph in {{% callout note %}} ... {{% /callout %}}, it will render as an aside.\n{{% callout note %}}\rA Markdown aside is useful for displaying notices, hints, or definitions to your readers.\r{{% /callout %}}\r renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}}\rYou found me!\r{{\u0026lt; /spoiler \u0026gt;}}\r renders as\nClick to view the spoiler You found me!\n Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R\r renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://chuanfang-ning.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Chuanfang Ning"],"categories":[],"content":"from IPython.core.display import Image\rImage('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')\r    print(\u0026quot;Welcome to Academic!\u0026quot;)\r Welcome to Academic!\r Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/\rcd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/\rjupyter lab index.ipynb\r The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n---\rtitle: My post's title\rdate: 2019-09-01\r# Put any other Academic metadata here...\r---\r Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.\r Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://chuanfang-ning.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://chuanfang-ning.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Research Assistant at Research Institution for Intelligent Autonomous Systems, Shanghai under Intelligent Manufacturing Grant\rSupervisor: Prof. Nan Xie\rProject goal The project aims at simulating the intelligent factory processing pipeline with a miniature model from Fischer.\nProject contents  implemented distributed control for multi-processing stations on SIEMENS PLC S-1500. programed intelligent ware management, processing and sorting pipeline with TIA Portal. developed a human-model interface for the industrial process control with SIEMENS Comfort Panel. Interactive control of industrial process with Virtual Reality.  Demo for industrial pipeline showcase   ","date":1544832000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544832000,"objectID":"54104257ab8936980ad5a2231023d84c","permalink":"https://chuanfang-ning.github.io/project/fischer-intelligent-factory/","publishdate":"2018-12-15T00:00:00Z","relpermalink":"/project/fischer-intelligent-factory/","section":"project","summary":"An example of using the in-built project page.","tags":["Automation Systems"],"title":"Fischer Intelligent Factory 4.0 Automation","type":"project"},{"authors":["Chuanfang Ning","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://chuanfang-ning.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://chuanfang-ning.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]